{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extact, Transform, Load (ETL) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_imdb_as_df(folder):\n",
    "    \"\"\"\n",
    "    loads pos and neg from either train or test\n",
    "    \n",
    "    Returns a Pandas dataframe with:\n",
    "    Colums = [Index, Word, Frequency, Rating, URL]\n",
    "    Rows = [int, st, int, int, str]\n",
    "    \"\"\"\n",
    "    colums = [\"ID\",\"Word\",\"Frequency\",\"Rating\",\"URL\"]\n",
    "    data = {}\n",
    "    #TODO: Implement\n",
    "    pass\n",
    "\n",
    "def reduce_imdb_data_dimensionality(df):\n",
    "    \"\"\"\n",
    "    Reduce dimensionality of set based on correlations and fequency\n",
    "    \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def reduce_news_data_dimensionality(n_categories=5, min_word_freq=10):\n",
    "    \"\"\"\n",
    "    Bring down size of sk learn dataset by:\n",
    "    - Picking 5 categories\n",
    "    - Filtering out rare words\n",
    "    \"\"\"\n",
    "    data = sk.datasets.fetch_20newsgroups(subset='train',remove=(['headers', 'footers', 'quotes']))\n",
    "    df = pd.DataFrame(data.data, columns = [\"Text\"])\n",
    "    print(df.head())\n",
    "    # Remove rare words\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn' has no attribute 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mreduce_news_data_dimensionality\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m, in \u001b[0;36mreduce_news_data_dimensionality\u001b[0;34m(n_categories, min_word_freq)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_news_data_dimensionality\u001b[39m(n_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_word_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Bring down size of sk learn dataset by:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    - Picking 5 categories\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    - Filtering out rare words\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mfetch_20newsgroups(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,remove\u001b[38;5;241m=\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfooters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     28\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m.\u001b[39mdata, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn' has no attribute 'datasets'"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "reduce_news_data_dimensionality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Plotting Functions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_classification(df):\n",
    "    \"\"\"\n",
    "    use Receiver Operating Characteristic (ROC) curve and area under the ROC curve (AUROC)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def evaluate_multiclass_classification(df):\n",
    "    \"\"\"\n",
    "    compute classification accuracy\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binary_classification(results):\n",
    "    \"\"\"\n",
    "    plot ROC curve\n",
    "    compare to DT from sklearn\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_multiclass_classification(results):\n",
    "    \"\"\"\n",
    "    compare accuracy to DT from sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_simple(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features from the Simple linear regression on the IMDB data\n",
    "    \n",
    "    Characteristics:\n",
    "    - 10 most positive and negative coefficients as the x-axis \n",
    "    - Feature names (i.e., words) as the y-axis  \n",
    "    \"\"\"\n",
    "    \n",
    "def plot_model_convergence(results, learning_rate):\n",
    "    \"\"\"\n",
    "    Convergence plot on how the logistic and multiclass regression converge given a reason- ably chosen learning rate.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_roc_curve(results):\n",
    "    \"\"\"\n",
    "    A single plot containing two ROC curves of logistic regression and sklearn-DT (Decision Trees) on the IMDB test data.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_auroc(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the AUROC of logistic regression and DT on the test data (y-axis) \n",
    "    as a function of the 20%, 40%, 60%, 80%, and 100% training data (x-axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_news_data_classification_accuracy(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the classification accuracies of multiclass regression and DT \n",
    "    on the test data (y-axis) as a function of the 20%, 40%, 60%, 80%, and 100% training data (x- axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_logistic(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features (10 most positive and 10 most negative) \n",
    "    from the logistic regression on the IMDB data with the coefficient as the x-axis and the feature names (i.e., words) as the y-axis\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_heatmap_of_multi_classification(results):\n",
    "    \"\"\"\n",
    "    A heatmap showing the top 5 most positive features as rows for each class as columns in the multi-class classification \n",
    "    on 4 the chosen classes from the 20-news group datasets. Therefore, your heatmap should be a 20-by-4 dimension.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_one():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - top 10 features with the most positive coefficients\n",
    "    - top 10 features with the most negative coefficients \n",
    "    \n",
    "    on the IMDB data using simple linear regression on the movie rating scores\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_two():\n",
    "    \"\"\"\n",
    "    Implement and conduct:\n",
    "    - Binary classification on the IMDb Reviews\n",
    "    - Multi-class classification on the 20 news group dataset\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_three():\n",
    "    \"\"\"\n",
    "    On the same plot as 2, draw ROC curves and report the AUROC \n",
    "    values of logistic regression and Decision Trees on the \n",
    "    IMDB data binary classification task\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_four():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - Multiclass classification accuracy of multiclass linear regression \n",
    "    - Decision Trees on the 5 chosen classes from the 20-news-group data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_five():\n",
    "    \"\"\"\n",
    "    Plot and compare the accuracy of the two models as a function of the\n",
    "    size of dataset by controlling the training size\n",
    "    \n",
    "    For example, you can randomly select 20%, 40%, 60% and 80% of the available \n",
    "    training data and train your model on this subset and evaluate the trained \n",
    "    model on the held-out test set.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_six():\n",
    "    \"\"\"\n",
    "    Compare and evaluate the performance of different learning rates\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_seven():\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the multiclass regression on more than 5 classes\n",
    "    \n",
    "    Compare the top k (e.g. k =3) predicted classes. \n",
    "    A correct prediction is determined by whether the true label is within the top k predicted labels. \n",
    "    The scoring mechanism involves assigning a score of 1 if the correct label is among the top k predictions and 0 otherwise.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
