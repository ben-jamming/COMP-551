{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import os\n",
    "from LinearRegression import LinearRegression\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from LogisticRegression import LogisticRegression as LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from MultiClassRegression import MultiClassRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extact, Transform, Load (ETL) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS = [1, 2, 3, 4, 7, 8, 9, 10]\n",
    "\n",
    "def extract_word_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "def parse_features_and_labels(feature_path='../aclImdb/test/labeledBow.feat'):\n",
    "    \"\"\"\n",
    "    Parse the feature file to extract word frequencies and labels for each review.\n",
    "    \n",
    "    Args:\n",
    "    - feature_path (str): Path to the feature file.\n",
    "    \n",
    "    Returns:\n",
    "    - List of dictionaries with 'label' and 'features' keys.\n",
    "    \"\"\"\n",
    "    reviews_data = []\n",
    "    with open(feature_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            label, *features = line.strip().split()\n",
    "            review_data = {\n",
    "                'label': int(label),\n",
    "                'features': {int(f.split(':')[0]): int(f.split(':')[1]) for f in features}\n",
    "            }\n",
    "            reviews_data.append(review_data)\n",
    "    return reviews_data\n",
    "\n",
    "def filter_features(reviews_data, min_feature_frequency=0.01, max_feature_frequency=0.5):\n",
    "    \"\"\"\n",
    "    Filters out features (words) that occur in less than 1% of the reviews or more than 50% of the reviews.\n",
    "    \n",
    "    Args:\n",
    "    - reviews_data (List[Dict]): List of dictionaries, each representing a review with word frequencies.\n",
    "    - min_feature_frequency (float): Minimum frequency threshold as a fraction of total reviews.\n",
    "    - max_feature_frequency (float): Maximum frequency threshold as a fraction of total reviews.\n",
    "    \n",
    "    Returns:\n",
    "    - A filtered list of dictionaries, with each dictionary representing a review and containing only the features that meet the frequency criteria.\n",
    "    \"\"\"\n",
    "    total_reviews = len(reviews_data)\n",
    "    word_occurrences = defaultdict(int)\n",
    "\n",
    "    # Count the number of reviews each word appears in\n",
    "    for review in reviews_data:\n",
    "        for word_index in review['features']:\n",
    "            word_occurrences[word_index] += 1\n",
    "\n",
    "    # Calculate frequency thresholds\n",
    "    min_reviews_threshold = total_reviews * min_feature_frequency\n",
    "    max_reviews_threshold = total_reviews * max_feature_frequency\n",
    "\n",
    "    # Identify words that meet the frequency criteria\n",
    "    valid_words = {word_index for word_index, count in word_occurrences.items()\n",
    "                   if min_reviews_threshold <= count <= max_reviews_threshold}\n",
    "\n",
    "    # Filter reviews to only include valid words\n",
    "    filtered_reviews_data = []\n",
    "    for review in reviews_data:\n",
    "        filtered_features = {word_index: count for word_index, count in review['features'].items()\n",
    "                             if word_index in valid_words}\n",
    "        filtered_review = {'label': review['label'], 'features': filtered_features}\n",
    "        filtered_reviews_data.append(filtered_review)\n",
    "\n",
    "    return filtered_reviews_data\n",
    "\n",
    "def create_frequency_dataframe(reviews_data):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from review data with word frequencies for each label.\n",
    "    \n",
    "    Args:\n",
    "    - reviews_data (List[Dict]): Parsed review data including labels and features.\n",
    "    \n",
    "    Returns:\n",
    "    - A pandas DataFrame with word indices as rows, labels as columns, and frequencies as cell values.\n",
    "    \"\"\"\n",
    "    word_label_freq = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for review in reviews_data:\n",
    "        label = review['label']\n",
    "        for word_index, count in review['features'].items():\n",
    "            word_label_freq[word_index][label] += count\n",
    "            \n",
    "    data = []\n",
    "    for word_index, label_freqs in word_label_freq.items():\n",
    "        for label, freq in label_freqs.items():\n",
    "            data.append({'word_index': word_index, 'label': label, 'frequency': freq})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df_pivoted = df.pivot(index='word_index', columns='label', values='frequency').fillna(0)\n",
    "\n",
    "    for rating in RATINGS:\n",
    "        if rating not in df_pivoted.columns:\n",
    "            df_pivoted[rating] = 0.0\n",
    "    df_pivoted = df_pivoted[RATINGS]\n",
    "\n",
    "    return df_pivoted\n",
    "\n",
    "def add_words_to_dataframe(df, word_data_path='../aclImdb/imdb.vocab', debug=False):\n",
    "    \"\"\"\n",
    "    Add words to the DataFrame as a new column, matching the index of each word in the vocab file\n",
    "    to the word index in the DataFrame.\n",
    "    If a word occurs in the vocab file but not the dataframe, don't add it to the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame with word frequencies for each label.\n",
    "    - word_data_path (str): Path to the vocab file.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame with a new 'word' column.\n",
    "    \"\"\"\n",
    "    words = extract_word_data(word_data_path)\n",
    "    index_to_word = {index+1: word for index, word in enumerate(words)}\n",
    "    df['word'] = df.index.map(index_to_word)\n",
    "    \n",
    "    if debug:\n",
    "        # Correct debug check: Verify all DataFrame indices have corresponding words in vocab\n",
    "        vocab_indices_set = set(index_to_word.keys())\n",
    "        dataframe_indices_set = set(df.index.astype(int))  # Ensure type alignment for comparison\n",
    "        \n",
    "        missing_indices_in_vocab = dataframe_indices_set - vocab_indices_set\n",
    "        if missing_indices_in_vocab:\n",
    "            print(f\"Warning: {len(missing_indices_in_vocab)} indices in DataFrame not found in vocab file.\")\n",
    "            \n",
    "        missing_indices_in_df = vocab_indices_set - dataframe_indices_set\n",
    "        if missing_indices_in_df:\n",
    "            print(f\"Note: {len(missing_indices_in_df)} indices in vocab file not represented in DataFrame. This may be expected due to filtering.\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def evaluate_binary_classification(df, encoder, model):\n",
    "    \"\"\"Evaluate binary classification using ROC curve and AUROC.\"\"\"\n",
    "    X = encoder.transform(df[['feature_index']])\n",
    "    y = df['sentiment']\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Assume get_test_data() is defined to return test features and labels\n",
    "    test_features, test_labels = get_test_data(encoder)  # Define this function based on your needs\n",
    "    predictions = model.predict(test_features)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(test_labels, predictions)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    return fpr, tpr, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: 87806 indices in vocab file not represented in DataFrame. This may be expected due to filtering.\n",
      "1721\n",
      "label          1     2     3     4     7     8     9    10 word\n",
      "word_index                                                     \n",
      "21          4562  2367  2899  3250  3425  3886  2931  5066  you\n",
      "23          3572  2042  2733  3323  3794  4128  3357  5211  are\n",
      "27          6765  2272  2014  1873  1435  2038  1830  6375  one\n",
      "30          3449  1844  2228  2600  2462  2925  2252  4064   at\n",
      "31          3504  1863  2364  2497  2352  2832  2215  3764   by\n"
     ]
    }
   ],
   "source": [
    "reviews_data = parse_features_and_labels()\n",
    "filtered_reviews_data = filter_features(reviews_data)\n",
    "df = create_frequency_dataframe(filtered_reviews_data)\n",
    "df = add_words_to_dataframe(df, debug=True)\n",
    "print(len(df))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Plotting Functions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_multiclass_classification(df):\n",
    "    \"\"\"\n",
    "    compute classification accuracy\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def plot_word_distribution(df, column='frequency'):\n",
    "    \"\"\"\n",
    "    Plot the distribution of word frequencies using Seaborn.\n",
    "\n",
    "    Args:\n",
    "    - df (DataFrame): DataFrame containing word frequencies.\n",
    "    - column (str): The column name in df that contains the word frequencies.\n",
    "    \"\"\"\n",
    "    # Setting the style of seaborn\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    # Creating the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column], bins=30, kde=True)\n",
    "\n",
    "    # Adding plot title and labels\n",
    "    plt.title('Distribution of Word Frequencies')\n",
    "    plt.xlabel('Word Frequency')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_training_progress(logistic_regression_model):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(logistic_regression_model.loss_history, label='Loss', color='b', ls='-',linewidth=1)\n",
    "    plt.title('Loss Progress over Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(logistic_regression_model.gradient_norm_history, label='Gradient Norm')\n",
    "    plt.title('Gradient Norm Progress over Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Gradient Norm')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_binary_classification(results):\n",
    "    \"\"\"\n",
    "    plot ROC curve\n",
    "    compare to DT from sklearn\n",
    "    \n",
    "    Args:\n",
    "    - results: tuple of fpr, tpr, auroc\n",
    "    \n",
    "    Return:\n",
    "    - None, plot the ROC curve\n",
    "    \n",
    "    \"\"\"\n",
    "    fpr, tpr, auroc = results\n",
    "    print(f\"Area under the ROC curve: {auroc}\")\n",
    "    print(f\"True positive rate: {tpr}\")\n",
    "    print(f\"False positive rate: {fpr}\")\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auroc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_multiclass_classification(results):\n",
    "    \"\"\"\n",
    "    compare accuracy to DT from sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_simple(top_positive_features, top_negative_features):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features from the Simple linear regression on the IMDB data\n",
    "    \n",
    "    Characteristics:\n",
    "    - 10 most positive and negative coefficients as the x-axis \n",
    "    - Feature names (i.e., words) as the y-axis  \n",
    "    \"\"\"\n",
    "    # Plot the top 20 positive and negative features on the same plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # assign each a different color and make negatives positive\n",
    "    top_negative_features['Impact'] = top_negative_features['Impact'].abs()\n",
    "    plt.barh(top_positive_features['Word'].head(10), top_positive_features['Impact'].head(10), color='b', label='Positive Impact')\n",
    "    plt.barh(top_negative_features['Word'].head(10), top_negative_features['Impact'].head(10), color='r', label='Negative Impact')\n",
    "    plt.xlabel('Regression Coefficients (Absolute Value)')\n",
    "    plt.ylabel('Word')\n",
    "    plt.title('Top 20 Features from Simple Linear Regression')\n",
    "    plt.legend()\n",
    "    #plt.savefig('top_20_features_from_imdb_simple.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_model_convergence(results, learning_rate):\n",
    "    \"\"\"\n",
    "    Convergence plot on how the logistic and multiclass regression converge given a reason- ably chosen learning rate.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_roc_curve(results):\n",
    "    \"\"\"\n",
    "    A single plot containing two ROC curves of logistic regression and sklearn-DT (Decision Trees) on the IMDB test data.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_auroc(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the AUROC of logistic regression and DT on the test data (y-axis) \n",
    "    as a function of the 20%, 40%, 60%, 80%, and 100% training data (x-axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_news_data_classification_accuracy(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the classification accuracies of multiclass regression and DT \n",
    "    on the test data (y-axis) as a function of the 20%, 40%, 60%, 80%, and 100% training data (x- axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_logistic(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features (10 most positive and 10 most negative) \n",
    "    from the logistic regression on the IMDB data with the coefficient as the x-axis and the feature names (i.e., words) as the y-axis\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_heatmap_of_multi_classification(results):\n",
    "    \"\"\"\n",
    "    A heatmap showing the top 5 most positive features as rows for each class as columns in the multi-class classification \n",
    "    on 4 the chosen classes from the 20-news group datasets. Therefore, your heatmap should be a 20-by-4 dimension.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_training_progress(\u001b[43mmodel\u001b[49m)\n\u001b[1;32m      2\u001b[0m plot_binary_classification(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_training_progress(model)\n",
    "plot_binary_classification(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_one():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - top 10 features with the most positive coefficients\n",
    "    - top 10 features with the most negative coefficients \n",
    "    \n",
    "    on the IMDB data using simple linear regression on the movie rating scores\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_two():\n",
    "    \"\"\"\n",
    "    Implement and conduct:\n",
    "    - Binary classification on the IMDb Reviews\n",
    "    - Multi-class classification on the 20 news group dataset\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_three():\n",
    "    \"\"\"\n",
    "    On the same plot as 2, draw ROC curves and report the AUROC \n",
    "    values of logistic regression and Decision Trees on the \n",
    "    IMDB data binary classification task\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_four():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - Multiclass classification accuracy of multiclass linear regression \n",
    "    - Decision Trees on the 5 chosen classes from the 20-news-group data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_five():\n",
    "    \"\"\"\n",
    "    Plot and compare the accuracy of the two models as a function of the\n",
    "    size of dataset by controlling the training size\n",
    "    \n",
    "    For example, you can randomly select 20%, 40%, 60% and 80% of the available \n",
    "    training data and train your model on this subset and evaluate the trained \n",
    "    model on the held-out test set.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_six():\n",
    "    \"\"\"\n",
    "    Compare and evaluate the performance of different learning rates\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_seven():\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the multiclass regression on more than 5 classes\n",
    "    \n",
    "    Compare the top k (e.g. k =3) predicted classes. \n",
    "    A correct prediction is determined by whether the true label is within the top k predicted labels. \n",
    "    The scoring mechanism involves assigning a score of 1 if the correct label is among the top k predictions and 0 otherwise.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
