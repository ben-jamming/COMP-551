{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import os\n",
    "from LinearRegression import LinearRegression\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from LogisticRegression import LogisticRegression\n",
    "from MultiClassRegression import MultiClassRegression\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extact, Transform, Load (ETL) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change RATINGS\n",
    "RATINGS = [1,2,3,4,7,8,9,10]\n",
    "\n",
    "def extract_word_data(file_path):\n",
    "    \"\"\"Extract word data from .vocab file and return as a list.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        words = f.read().splitlines()\n",
    "    return words\n",
    "\n",
    "def get_correlations(df):\n",
    "    \"\"\" Get the correlation between the word and the ratings\"\"\"\n",
    "    correlations = []\n",
    "    for _, row in df.iterrows():\n",
    "        X = np.array(RATINGS).reshape(-1, 1).astype(float)\n",
    "        y = row[RATINGS].values.astype(float)\n",
    "        correlation = np.corrcoef(X.flatten(), y)[0, 1]\n",
    "        correlations.append(correlation)\n",
    "        \n",
    "    # Add the correlation to the DataFrame\n",
    "    df['correlation'] = correlations\n",
    "    return df\n",
    "\n",
    "def process_imdb_data(feat_file_path, vocab_file_path):\n",
    "    words = extract_word_data(vocab_file_path)\n",
    "    index_word_dict = {index: word for index, word in enumerate(words)}\n",
    "    \n",
    "    # Read in the .feat file\n",
    "    with open(feat_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    total_docs = len(lines)\n",
    "    print(f\"Total documents: {total_docs}\")\n",
    "    \n",
    "    # Initialize a dictionary to store the counts of each word across all ratings and document count\n",
    "    word_counts = {}\n",
    "    for line in lines:\n",
    "        rating = int(line.split()[0])\n",
    "        word_count_pairs = line.split()[1:]\n",
    "        document_words = set()  # To keep track of words in this document\n",
    "        \n",
    "        for pair in word_count_pairs:\n",
    "            word_index, count = map(int, pair.split(\":\"))\n",
    "            document_words.add(word_index)\n",
    "            \n",
    "            if word_index not in word_counts:\n",
    "                word_counts[word_index] = {'doc_count': 1, rating: count}\n",
    "            else:\n",
    "                if rating not in word_counts[word_index]:\n",
    "                    word_counts[word_index][rating] = count\n",
    "                else:\n",
    "                    word_counts[word_index][rating] += count\n",
    "        \n",
    "        # Update document count for words in this document\n",
    "        for word_index in document_words:\n",
    "            if 'doc_count' in word_counts[word_index]:\n",
    "                word_counts[word_index]['doc_count'] += 1\n",
    "            else:\n",
    "                word_counts[word_index]['doc_count'] = 1\n",
    "                \n",
    "    # Prepare data for DataFrame creation\n",
    "    df_data = []\n",
    "    for word_index, counts in word_counts.items():\n",
    "        row = [index_word_dict.get(word_index, \"Unknown\"), counts.pop('doc_count')] + [counts.get(rating, 0) for rating in RATINGS]\n",
    "        df_data.append(row)\n",
    "    \n",
    "    # Create DataFrame with correct columns, including 'word' and 'word_doc_count' as the first columns\n",
    "    df = pd.DataFrame(df_data, columns=['word', 'word_doc_count'] + RATINGS)\n",
    "    df = get_correlations(df)\n",
    "    df = filter_words(df, total_docs)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_words(df, total_docs):\n",
    "    \"\"\"Filter words based on document frequency and variance in frequencies.\"\"\"\n",
    "    # Convert 'word_doc_count' to document frequency by dividing by total_docs\n",
    "    df['doc_frequency'] = df['word_doc_count'] / total_docs\n",
    "    \n",
    "    # Calculate the variance or standard deviation of frequencies across ratings for each word\n",
    "    df['frequency_std'] = df[RATINGS].std(axis=1)\n",
    "    \n",
    "    # Adjusted Filter criteria\n",
    "    min_doc_presence = 0.01  # Adjusted minimum document presence\n",
    "    max_doc_presence = 0.6   # Maximum document presence remains the same\n",
    "    min_frequency_std = 0.6  # Minimum standard deviation of frequencies across ratings\n",
    "    min_correlation = 0.85    # Minimum correlation with ratings\n",
    "    \n",
    "    # Filter the DataFrame to keep only the selected words based on criteria\n",
    "    filtered_df = df[(df['doc_frequency'] > min_doc_presence) & \n",
    "                 (df['doc_frequency'] < max_doc_presence) & \n",
    "                 (df['frequency_std'] > min_frequency_std) &\n",
    "                 ((df['correlation'] > min_correlation) | (df['correlation'] < -min_correlation))]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def reduce_imdb_data_dimensionality(df, n_features=500):\n",
    "    \"\"\"Reduce dimensionality of the dataset based on regression coefficients.\"\"\"\n",
    "    model = LinearRegression()\n",
    "    coefficients = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        X = np.array(RATINGS).reshape(-1, 1).astype(float)\n",
    "        y = row[RATINGS].values.astype(float)\n",
    "        model.fit(X, y)\n",
    "        impact = model.w[0]\n",
    "        absolute_impact = abs(impact)\n",
    "        correlation = row['correlation']\n",
    "        coefficients.append({\n",
    "            'Word': row['word'],\n",
    "            'Impact': impact,\n",
    "            'Absolute Impact': absolute_impact,\n",
    "            'Correlation': correlation\n",
    "        })\n",
    "\n",
    "    coef_df = pd.DataFrame(coefficients)\n",
    "    top_positive_features = pd.DataFrame(coef_df, columns=[ 'Word', 'Impact','Absolute Impact','Correlation']).sort_values(by='Impact', ascending=False).head(n_features)\n",
    "    top_negative_features = pd.DataFrame(coef_df, columns=['Word', 'Impact','Absolute Impact','Correlation']).sort_values(by='Impact', ascending=True).head(n_features)\n",
    "    top_abs_features = pd.DataFrame(coef_df, columns=['Word', 'Impact','Absolute Impact','Correlation']).sort_values(by='Absolute Impact', ascending=False).head(n_features)\n",
    "    return top_positive_features, top_negative_features, top_abs_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 25000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = process_imdb_data(\"../aclImdb/train/labeledBow.feat\",\"../aclImdb/imdb.vocab\")\n",
    "#print(results.sort_values(by='frequency', ascending=False).head(10))\n",
    "#print(results.shape)\n",
    "top_positive_features, top_negative_features, top_absolute_features = reduce_imdb_data_dimensionality(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Features\n",
      "            Word     Impact  Absolute Impact  Correlation\n",
      "3      excellent  53.945122        53.945122     0.908437\n",
      "2          young  41.024390        41.024390     0.876922\n",
      "10   performance  40.097561        40.097561     0.867315\n",
      "30       perfect  36.524390        36.524390     0.864079\n",
      "24  performances  26.902439        26.902439     0.898885\n",
      "0      fantastic  22.597561        22.597561     0.851958\n",
      "16        superb  21.054878        21.054878     0.859257\n",
      "8        enjoyed  19.780488        19.780488     0.868926\n",
      "11        strong  16.091463        16.091463     0.901589\n",
      "86        simple  14.987805        14.987805     0.851459\n",
      "Top Negative Features\n",
      "        Word     Impact  Absolute Impact  Correlation\n",
      "74    boring -48.317073        48.317073    -0.884543\n",
      "57      poor -44.030488        44.030488    -0.866326\n",
      "38  supposed -36.585366        36.585366    -0.882679\n",
      "19   instead -31.865854        31.865854    -0.858675\n",
      "85  annoying -24.621951        24.621951    -0.937706\n",
      "66      lame -24.109756        24.109756    -0.870875\n",
      "41    poorly -23.774390        23.774390    -0.898581\n",
      "79     cheap -19.682927        19.682927    -0.879931\n",
      "81      dull -19.274390        19.274390    -0.906483\n",
      "13      mess -18.463415        18.463415    -0.887195\n",
      "Top Absolute Features\n",
      "            Word     Impact  Absolute Impact  Correlation\n",
      "3      excellent  53.945122        53.945122     0.908437\n",
      "74        boring -48.317073        48.317073    -0.884543\n",
      "57          poor -44.030488        44.030488    -0.866326\n",
      "2          young  41.024390        41.024390     0.876922\n",
      "10   performance  40.097561        40.097561     0.867315\n",
      "38      supposed -36.585366        36.585366    -0.882679\n",
      "30       perfect  36.524390        36.524390     0.864079\n",
      "19       instead -31.865854        31.865854    -0.858675\n",
      "24  performances  26.902439        26.902439     0.898885\n",
      "85      annoying -24.621951        24.621951    -0.937706\n",
      "Word 'bad' not found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Positive Features\")\n",
    "print(top_positive_features.head(10))\n",
    "print(\"Top Negative Features\")\n",
    "print(top_negative_features.head(10))\n",
    "print(\"Top Absolute Features\")\n",
    "print(top_absolute_features.head(10))\n",
    "\n",
    "plot_word_regression(results, \"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Plotting Functions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_classification(df):\n",
    "    \"\"\"\n",
    "    use Receiver Operating Characteristic (ROC) curve and area under the ROC curve (AUROC)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def evaluate_multiclass_classification(df):\n",
    "    \"\"\"\n",
    "    compute classification accuracy\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binary_classification(results):\n",
    "    \"\"\"\n",
    "    plot ROC curve\n",
    "    compare to DT from sklearn\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_multiclass_classification(results):\n",
    "    \"\"\"\n",
    "    compare accuracy to DT from sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_simple(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features from the Simple linear regression on the IMDB data\n",
    "    \n",
    "    Characteristics:\n",
    "    - 10 most positive and negative coefficients as the x-axis \n",
    "    - Feature names (i.e., words) as the y-axis  \n",
    "    \"\"\"\n",
    "    \n",
    "def plot_model_convergence(results, learning_rate):\n",
    "    \"\"\"\n",
    "    Convergence plot on how the logistic and multiclass regression converge given a reason- ably chosen learning rate.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_roc_curve(results):\n",
    "    \"\"\"\n",
    "    A single plot containing two ROC curves of logistic regression and sklearn-DT (Decision Trees) on the IMDB test data.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_auroc(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the AUROC of logistic regression and DT on the test data (y-axis) \n",
    "    as a function of the 20%, 40%, 60%, 80%, and 100% training data (x-axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_news_data_classification_accuracy(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the classification accuracies of multiclass regression and DT \n",
    "    on the test data (y-axis) as a function of the 20%, 40%, 60%, 80%, and 100% training data (x- axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_logistic(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features (10 most positive and 10 most negative) \n",
    "    from the logistic regression on the IMDB data with the coefficient as the x-axis and the feature names (i.e., words) as the y-axis\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_heatmap_of_multi_classification(results):\n",
    "    \"\"\"\n",
    "    A heatmap showing the top 5 most positive features as rows for each class as columns in the multi-class classification \n",
    "    on 4 the chosen classes from the 20-news group datasets. Therefore, your heatmap should be a 20-by-4 dimension.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_one():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - top 10 features with the most positive coefficients\n",
    "    - top 10 features with the most negative coefficients \n",
    "    \n",
    "    on the IMDB data using simple linear regression on the movie rating scores\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_two():\n",
    "    \"\"\"\n",
    "    Implement and conduct:\n",
    "    - Binary classification on the IMDb Reviews\n",
    "    - Multi-class classification on the 20 news group dataset\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_three():\n",
    "    \"\"\"\n",
    "    On the same plot as 2, draw ROC curves and report the AUROC \n",
    "    values of logistic regression and Decision Trees on the \n",
    "    IMDB data binary classification task\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_four():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - Multiclass classification accuracy of multiclass linear regression \n",
    "    - Decision Trees on the 5 chosen classes from the 20-news-group data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_five():\n",
    "    \"\"\"\n",
    "    Plot and compare the accuracy of the two models as a function of the\n",
    "    size of dataset by controlling the training size\n",
    "    \n",
    "    For example, you can randomly select 20%, 40%, 60% and 80% of the available \n",
    "    training data and train your model on this subset and evaluate the trained \n",
    "    model on the held-out test set.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_six():\n",
    "    \"\"\"\n",
    "    Compare and evaluate the performance of different learning rates\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_seven():\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the multiclass regression on more than 5 classes\n",
    "    \n",
    "    Compare the top k (e.g. k =3) predicted classes. \n",
    "    A correct prediction is determined by whether the true label is within the top k predicted labels. \n",
    "    The scoring mechanism involves assigning a score of 1 if the correct label is among the top k predictions and 0 otherwise.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
