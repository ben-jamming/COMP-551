{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import os\n",
    "from LinearRegression import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "#from LogisticRegression import LogisticRegression as LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from MultiClassRegression import MultiClassRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extact, Transform, Load (ETL) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_vocab(vocab_file_path):\n",
    "    \"\"\"\n",
    "    Loads the vocabulary from a file and creates two dictionaries: \n",
    "    one mapping indices to words and another mapping words to indices.\n",
    "    \"\"\"\n",
    "    index_to_feature_map = {}\n",
    "    with open(vocab_file_path, 'r', encoding='utf-8') as vocab_file:\n",
    "        for index, word in enumerate(vocab_file):\n",
    "            index_to_feature_map[str(index)] = word.strip()\n",
    "    feature_to_index_map = {word: index for index, word in index_to_feature_map.items()}\n",
    "    return index_to_feature_map, feature_to_index_map\n",
    "\n",
    "def parse_review_features(line):\n",
    "    features = line.strip().split()[1:]  # Skip the first element (label)\n",
    "    return [feature.split(':') for feature in features]\n",
    "\n",
    "def compute_review_frequencies(feature_path):\n",
    "    \"\"\"\n",
    "    Computes the frequency of each word across reviews.\n",
    "    \"\"\"\n",
    "    review_frequencies = defaultdict(int)\n",
    "    total_reviews = 0\n",
    "    with open(feature_path, 'r', encoding='utf-8') as feat_file:\n",
    "        for line in feat_file:\n",
    "            total_reviews += 1\n",
    "            for index, _ in parse_review_features(line):\n",
    "                review_frequencies[index] += 1\n",
    "    return review_frequencies, total_reviews\n",
    "\n",
    "def filter_feature_indices(review_frequencies, total_reviews, lower_bound=0.01, upper_bound=0.5):\n",
    "    \"\"\"\n",
    "    Filters out feature indices based on review frequency criteria.\n",
    "    \"\"\"\n",
    "    min_reviews = total_reviews * lower_bound\n",
    "    max_reviews = total_reviews * upper_bound\n",
    "    filtered_feature_indices = {index for index, freq in review_frequencies.items() \n",
    "                                if min_reviews <= freq <= max_reviews}\n",
    "\n",
    "    return sorted([int(i) for i in filtered_feature_indices])\n",
    "\n",
    "def load_review_features(feature_path, index_mapping, n_reviews, n_features):\n",
    "    \"\"\"\n",
    "    Loads review features and labels into matrices based on a filtered and remapped vocabulary.\n",
    "    \"\"\"\n",
    "    X = np.zeros((n_reviews, n_features))\n",
    "    y = np.zeros(n_reviews)\n",
    "    with open(feature_path, 'r') as file:\n",
    "        for review_id, line in enumerate(file):\n",
    "            parts = line.strip().split()\n",
    "            y[review_id] = int(parts[0])  # First part is the label\n",
    "            for index, count in parse_review_features(line):\n",
    "                if index in index_mapping:\n",
    "                    X[review_id, index_mapping[index]] = int(count)\n",
    "    return X, y\n",
    "\n",
    "def filter_by_regression_coefficients(X, y, D=250):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    coefficients = model.w[:-1]\n",
    "    top_indices = np.argsort(np.abs(coefficients))[-D:]\n",
    "    return top_indices, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define globals\n",
    "VOCAB_FILE = '../aclImdb/imdb.vocab'\n",
    "TRAIN_FEAT = '../aclImdb/train/labeledBow.feat'\n",
    "TEST_FEAT = '../aclImdb/test/labeledBow.feat'\n",
    "N_REVIEWS = 25000\n",
    "\n",
    "# load the data and filter the reviews\n",
    "index_to_feature_map, feature_to_index_map = load_vocab(VOCAB_FILE)\n",
    "review_frequencies, total_reviews = compute_review_frequencies(TRAIN_FEAT)\n",
    "filtered_indices = filter_feature_indices(review_frequencies, total_reviews)\n",
    "index_mapping = {str(old_index): new_index for new_index, old_index in enumerate(filtered_indices)}\n",
    "\n",
    "# create train and test based on the filtered indices\n",
    "N_FEATURES = len(filtered_indices)\n",
    "X_train, y_train = load_review_features(TRAIN_FEAT, index_mapping, N_REVIEWS, N_FEATURES)\n",
    "X_test, y_test = load_review_features(TEST_FEAT, index_mapping, N_REVIEWS, N_FEATURES)\n",
    "\n",
    "# Now filter by the regression coefficients\n",
    "X_train_filtered, coefficients = filter_by_regression_coefficients(X_train, y_train)\n",
    "X_train_filtered = X_train_filtered[::-1]  # Reverse the order to get the top coefficients first\n",
    "reverse_index_mapping = {new_index: old_index for old_index, new_index in index_mapping.items()}\n",
    "\n",
    "for i in X_train_filtered:\n",
    "    original_index = reverse_index_mapping[i]  # Map from reduced space to original index\n",
    "    word = index_to_feature_map[str(original_index)]\n",
    "    coef = coefficients[i]\n",
    "    print(f\"{word}: coefficient = {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Plotting Functions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_multiclass_classification(df):\n",
    "    \"\"\"\n",
    "    compute classification accuracy\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_top_features(coefficients, sorted_indices, index_to_feature_map, reverse_index_mapping, n_features=10):\n",
    "    \"\"\"\n",
    "    Plots the top N negative and positive features based on their coefficients, with a legend.\n",
    "    \n",
    "    Parameters:\n",
    "    - coefficients: Array of feature coefficients from a regression model.\n",
    "    - index_to_feature_map: Dictionary mapping original feature indices to words.\n",
    "    - reverse_index_mapping: Dictionary mapping from reduced feature space to original index.\n",
    "    - n_features: Number of top features to plot for both negative and positive coefficients.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate positive and negative coefficients\n",
    "    positive_indices = [i for i, coef in enumerate(coefficients) if coef > 0]\n",
    "    negative_indices = [i for i, coef in enumerate(coefficients) if coef < 0]\n",
    "    \n",
    "    # Sort them by absolute values but keep the sign for color coding\n",
    "    top_positive_indices = sorted(positive_indices, key=lambda i: coefficients[i], reverse=True)[:n_features]\n",
    "    top_negative_indices = sorted(negative_indices, key=lambda i: coefficients[i])[:n_features]\n",
    "    \n",
    "    # Combine the indices and coefficients for plotting\n",
    "    top_indices = top_negative_indices + top_positive_indices\n",
    "    top_coefficients = [coefficients[i] for i in top_indices]\n",
    "    top_words = [index_to_feature_map[str(reverse_index_mapping[i])] for i in top_indices]\n",
    "    \n",
    "    # Determine colors based on coefficient sign\n",
    "    colors = ['red' if coef < 0 else 'blue' for coef in top_coefficients]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x=np.abs(top_coefficients), y=top_words, palette=colors, orient='h')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Top 20 Features by Absolute Coefficient Value From Linear Regression')\n",
    "    \n",
    "    # Create a custom legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='blue', edgecolor='blue', label='Positive'),\n",
    "                       Patch(facecolor='red', edgecolor='red', label='Negative')]\n",
    "    plt.legend(handles=legend_elements, title='Coefficient Sign')\n",
    "    plt.savefig('top_20_features.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_features(coefficients, X_train_filtered, index_to_feature_map, reverse_index_mapping ,n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_training_progress(logistic_regression_model):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(logistic_regression_model.loss_history, label='Loss', color='b', ls='-',linewidth=1)\n",
    "    plt.title('Loss Progress over Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(logistic_regression_model.gradient_norm_history, label='Gradient Norm')\n",
    "    plt.title('Gradient Norm Progress over Iterations')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Gradient Norm')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_binary_classification(results):\n",
    "    \"\"\"\n",
    "    plot ROC curve\n",
    "    compare to DT from sklearn\n",
    "    \n",
    "    Args:\n",
    "    - results: tuple of fpr, tpr, auroc\n",
    "    \n",
    "    Return:\n",
    "    - None, plot the ROC curve\n",
    "    \n",
    "    \"\"\"\n",
    "    fpr, tpr, auroc = results\n",
    "    print(f\"Area under the ROC curve: {auroc}\")\n",
    "    print(f\"True positive rate: {tpr}\")\n",
    "    print(f\"False positive rate: {fpr}\")\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auroc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_multiclass_classification(results):\n",
    "    \"\"\"\n",
    "    compare accuracy to DT from sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_simple(top_positive_features, top_negative_features):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features from the Simple linear regression on the IMDB data\n",
    "    \n",
    "    Characteristics:\n",
    "    - 10 most positive and negative coefficients as the x-axis \n",
    "    - Feature names (i.e., words) as the y-axis  \n",
    "    \"\"\"\n",
    "    # Plot the top 20 positive and negative features on the same plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # assign each a different color and make negatives positive\n",
    "    top_negative_features['Impact'] = top_negative_features['Impact'].abs()\n",
    "    plt.barh(top_positive_features['Word'].head(10), top_positive_features['Impact'].head(10), color='b', label='Positive Impact')\n",
    "    plt.barh(top_negative_features['Word'].head(10), top_negative_features['Impact'].head(10), color='r', label='Negative Impact')\n",
    "    plt.xlabel('Regression Coefficients (Absolute Value)')\n",
    "    plt.ylabel('Word')\n",
    "    plt.title('Top 20 Features from Simple Linear Regression')\n",
    "    plt.legend()\n",
    "    #plt.savefig('top_20_features_from_imdb_simple.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_model_convergence(results, learning_rate):\n",
    "    \"\"\"\n",
    "    Convergence plot on how the logistic and multiclass regression converge given a reason- ably chosen learning rate.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_roc_curve(results):\n",
    "    \"\"\"\n",
    "    A single plot containing two ROC curves of logistic regression and sklearn-DT (Decision Trees) on the IMDB test data.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_auroc(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the AUROC of logistic regression and DT on the test data (y-axis) \n",
    "    as a function of the 20%, 40%, 60%, 80%, and 100% training data (x-axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_news_data_classification_accuracy(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the classification accuracies of multiclass regression and DT \n",
    "    on the test data (y-axis) as a function of the 20%, 40%, 60%, 80%, and 100% training data (x- axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_logistic(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features (10 most positive and 10 most negative) \n",
    "    from the logistic regression on the IMDB data with the coefficient as the x-axis and the feature names (i.e., words) as the y-axis\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_heatmap_of_multi_classification(results):\n",
    "    \"\"\"\n",
    "    A heatmap showing the top 5 most positive features as rows for each class as columns in the multi-class classification \n",
    "    on 4 the chosen classes from the 20-news group datasets. Therefore, your heatmap should be a 20-by-4 dimension.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_progress(model)\n",
    "plot_binary_classification(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_one():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - top 10 features with the most positive coefficients\n",
    "    - top 10 features with the most negative coefficients \n",
    "    \n",
    "    on the IMDB data using simple linear regression on the movie rating scores\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_two():\n",
    "    \"\"\"\n",
    "    Implement and conduct:\n",
    "    - Binary classification on the IMDb Reviews\n",
    "    - Multi-class classification on the 20 news group dataset\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_three():\n",
    "    \"\"\"\n",
    "    On the same plot as 2, draw ROC curves and report the AUROC \n",
    "    values of logistic regression and Decision Trees on the \n",
    "    IMDB data binary classification task\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_four():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - Multiclass classification accuracy of multiclass linear regression \n",
    "    - Decision Trees on the 5 chosen classes from the 20-news-group data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_five():\n",
    "    \"\"\"\n",
    "    Plot and compare the accuracy of the two models as a function of the\n",
    "    size of dataset by controlling the training size\n",
    "    \n",
    "    For example, you can randomly select 20%, 40%, 60% and 80% of the available \n",
    "    training data and train your model on this subset and evaluate the trained \n",
    "    model on the held-out test set.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_six():\n",
    "    \"\"\"\n",
    "    Compare and evaluate the performance of different learning rates\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_seven():\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the multiclass regression on more than 5 classes\n",
    "    \n",
    "    Compare the top k (e.g. k =3) predicted classes. \n",
    "    A correct prediction is determined by whether the true label is within the top k predicted labels. \n",
    "    The scoring mechanism involves assigning a score of 1 if the correct label is among the top k predictions and 0 otherwise.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
