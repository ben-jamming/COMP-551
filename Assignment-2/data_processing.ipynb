{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import os\n",
    "from LinearRegression import LinearRegression\n",
    "from LogisticRegression import LogisticRegression\n",
    "from MultiClassRegression import MultiClassRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extact, Transform, Load (ETL) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_data(file_path):\n",
    "    \"\"\"\n",
    "    Extract word data from .vocab file\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array: (n_word_indices)\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        words = [line.split()[0] for line in lines]\n",
    "        \n",
    "    return np.array(words)   \n",
    "\n",
    "def processs_imdb_data(feat_file_path, vocab_file_path):\n",
    "    \"\"\"\n",
    "    The .vocab and .feat files contain enough information to create the features and labels.\n",
    "    However, to select the top n_features based on their regression coefficients we need to count the\n",
    "    number of times each word occurs with each rating.\n",
    "    \n",
    "    Right now, the .feat file is structured such that the first value contains the rating of that review and (word_index: count) pairs\n",
    "    We need to create a data frame where the columns are [word_index, 1,2,...,10] where the 1,..,10 represents the rating. The values of cols\n",
    "    1-10 will be the number of times the word_index occurs in a review with each respective rating\n",
    "    \n",
    "    Return:\n",
    "    - Pandas Dataframe: columns = [feature_index, 1,2,3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    \"\"\"\n",
    "    words = extract_word_data(vocab_file_path)\n",
    "    index_word_dict = {index: word for index, word in enumerate(words)}\n",
    "    \n",
    "    # Read in the .feat file\n",
    "    with open(feat_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        data = [line.split() for line in lines]\n",
    "        \n",
    "    # Create a nested dictionary to store the counts of each word with each rating\n",
    "    word_counts = {}\n",
    "    for line in data:\n",
    "        rating = int(line[0])\n",
    "        for word_count_pair in line[1:]:\n",
    "            word_index, count = map(int, word_count_pair.split(\":\"))\n",
    "            if word_index not in word_counts:\n",
    "                word_counts[word_index] = {rating: count}\n",
    "            else:\n",
    "                word_counts[word_index][rating] = word_counts[word_index].get(rating, 0) + count\n",
    "    \n",
    "    # Prepare data for DataFrame creation\n",
    "    df_data = []\n",
    "    ratings = [1,2,3,4,6,7,8,9,10]\n",
    "    for word_index, counts in word_counts.items():\n",
    "        row = [word_index, index_word_dict.get(word_index, \"Unknown\")] + [counts.get(rating, 0) for rating in ratings]\n",
    "        df_data.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df_data, columns=['feature_index','word'] + ratings)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    # # Sort the columns from 1-10\n",
    "    # df = df.reindex(sorted(df.columns), axis=1)\n",
    "    \n",
    "    # # get the word data and add it to the dataframe\n",
    "    # words = extract_word_data()\n",
    "    # # convert words to a dict mapping index to word\n",
    "    # n_words = len(words)\n",
    "    # words = {i: words[i] for i in range(n_words)}\n",
    "    # df = df.rename(columns=words)\n",
    "    # # Match the word index (current dataframe index values) to the word\n",
    "    \n",
    "    \n",
    "    # return df\n",
    "    \n",
    "\n",
    "def reduce_imdb_data_dimensionality(features, ratings, n_features=500):\n",
    "    \"\"\"\n",
    "    Reduce dimensionality of set based on the absolute regression coefficients\n",
    "    of the top n_features with the rating scores (1-10)\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "\n",
    "def reduce_news_data_dimensionality(n_categories=5, min_word_freq=10):\n",
    "    \"\"\"\n",
    "    Bring down size of sk learn dataset by:\n",
    "    - Picking 5 categories\n",
    "    - Filtering out rare words\n",
    "    \"\"\"\n",
    "    categories = ['comp.graphics' ,'rec.sport.hockey', 'sci.med', 'soc.religion.christian', 'talk.politics.guns']\n",
    "    data = sklearn.datasets.fetch_20newsgroups(subset='train',remove=(('headers', 'footers', 'quotes')))\n",
    "    df = pd.DataFrame(data.data, columns = [\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = processs_imdb_data(\"../aclImdb/train/labeledBow.feat\",\"../aclImdb/imdb.vocab\")\n",
    "# print the number of rows\n",
    "print(results.head(10)) \n",
    "print(results.shape)\n",
    "results.dropna(inplace=True)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Plotting Functions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_classification(df):\n",
    "    \"\"\"\n",
    "    use Receiver Operating Characteristic (ROC) curve and area under the ROC curve (AUROC)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def evaluate_multiclass_classification(df):\n",
    "    \"\"\"\n",
    "    compute classification accuracy\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binary_classification(results):\n",
    "    \"\"\"\n",
    "    plot ROC curve\n",
    "    compare to DT from sklearn\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_multiclass_classification(results):\n",
    "    \"\"\"\n",
    "    compare accuracy to DT from sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_simple(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features from the Simple linear regression on the IMDB data\n",
    "    \n",
    "    Characteristics:\n",
    "    - 10 most positive and negative coefficients as the x-axis \n",
    "    - Feature names (i.e., words) as the y-axis  \n",
    "    \"\"\"\n",
    "    \n",
    "def plot_model_convergence(results, learning_rate):\n",
    "    \"\"\"\n",
    "    Convergence plot on how the logistic and multiclass regression converge given a reason- ably chosen learning rate.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_roc_curve(results):\n",
    "    \"\"\"\n",
    "    A single plot containing two ROC curves of logistic regression and sklearn-DT (Decision Trees) on the IMDB test data.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_imdb_data_auroc(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the AUROC of logistic regression and DT on the test data (y-axis) \n",
    "    as a function of the 20%, 40%, 60%, 80%, and 100% training data (x-axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_news_data_classification_accuracy(results):\n",
    "    \"\"\"\n",
    "    A bar plot that shows the classification accuracies of multiclass regression and DT \n",
    "    on the test data (y-axis) as a function of the 20%, 40%, 60%, 80%, and 100% training data (x- axis)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_top_20_features_from_imdb_logistic(results):\n",
    "    \"\"\"\n",
    "    A horizontal bar plot showing the top 20 features (10 most positive and 10 most negative) \n",
    "    from the logistic regression on the IMDB data with the coefficient as the x-axis and the feature names (i.e., words) as the y-axis\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_heatmap_of_multi_classification(results):\n",
    "    \"\"\"\n",
    "    A heatmap showing the top 5 most positive features as rows for each class as columns in the multi-class classification \n",
    "    on 4 the chosen classes from the 20-news group datasets. Therefore, your heatmap should be a 20-by-4 dimension.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_one():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - top 10 features with the most positive coefficients\n",
    "    - top 10 features with the most negative coefficients \n",
    "    \n",
    "    on the IMDB data using simple linear regression on the movie rating scores\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_two():\n",
    "    \"\"\"\n",
    "    Implement and conduct:\n",
    "    - Binary classification on the IMDb Reviews\n",
    "    - Multi-class classification on the 20 news group dataset\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_three():\n",
    "    \"\"\"\n",
    "    On the same plot as 2, draw ROC curves and report the AUROC \n",
    "    values of logistic regression and Decision Trees on the \n",
    "    IMDB data binary classification task\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_four():\n",
    "    \"\"\"\n",
    "    Report the:\n",
    "    - Multiclass classification accuracy of multiclass linear regression \n",
    "    - Decision Trees on the 5 chosen classes from the 20-news-group data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_five():\n",
    "    \"\"\"\n",
    "    Plot and compare the accuracy of the two models as a function of the\n",
    "    size of dataset by controlling the training size\n",
    "    \n",
    "    For example, you can randomly select 20%, 40%, 60% and 80% of the available \n",
    "    training data and train your model on this subset and evaluate the trained \n",
    "    model on the held-out test set.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_six():\n",
    "    \"\"\"\n",
    "    Compare and evaluate the performance of different learning rates\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_seven():\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the multiclass regression on more than 5 classes\n",
    "    \n",
    "    Compare the top k (e.g. k =3) predicted classes. \n",
    "    A correct prediction is determined by whether the true label is within the top k predicted labels. \n",
    "    The scoring mechanism involves assigning a score of 1 if the correct label is among the top k predictions and 0 otherwise.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
